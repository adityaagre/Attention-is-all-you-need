# Attention Is All You Need

Developing a text generating transformer based on the transformer architecture in the paper "Attention is all you need" by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Also taking reference from Andrej Karpathy's repository.

Dataset: "Friends" Serial transcript.

# Version 1 : 
Here, the text is tokenised according to characters. Considering lowercase, uppercase and special characters, we have just under a 100 tokens.

# Version 2 :
Now, tokenisation is performed word-wise. now the entire transcript has 1154596 words. Since we are making each unique word a token, we have 27768 tokens. 

Still working on better versions. Stay Tuned :)
